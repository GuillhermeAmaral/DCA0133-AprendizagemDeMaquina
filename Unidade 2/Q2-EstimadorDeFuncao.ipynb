{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2\n",
    "Utilize redes neurais perceptrons de múltiplas camadas para aproximar as funções baixo. Para o caso dos itens 2 e 3, apresente a curva da função analítica e a curva da função aproximada pela rede neural. Apresente também a curva do erro médio de treinamento com relação ao número de épocas e a curva do erro médio com o conjunto de validação. Procure definir para cada função a arquitetura da rede neural perceptron, isto é, o número de entradas, o número de neurônios em cada camada e o número de neurônios na camada de saída.\n",
    "1. $f(x_{1}, x_{2}, x_{3}) = x_{1}\\oplus x_{2}\\oplus x_{3} \\;\\; x_{1}, x_{2} \\text{ e } x_{3} \\in \\left\\{0, 1\\right\\}$\n",
    "\n",
    "\n",
    "2. $f(x) = \\dfrac{\\cos 2\\pi x}{1-(4x)^{2}} \\dfrac{\\sin(\\pi x)}{\\pi x} \\;\\;,0\\leq x \\leq 4\\pi$\n",
    "\n",
    "\n",
    "3. $f(x_{1}, x_{2}) = x_{1}^{2} + x_{2}^{2} + 2x_{1}x_{2}\\cos (\\pi x_{1}x_{2}) + x_{1}+x_{2}-1 \\;\\;,|x_{1}|\\leq 1 \\text{ e } |x_{2}|\\leq 1$\n",
    "\n",
    "Logo abaixo estão as bibliotecas e funções comuns a solução de todos os itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import keras.callbacks as kc\n",
    "import keras.layers as kl\n",
    "import keras.models as km\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução da função 1 (TODO)\n",
    "Vamos gerar nossos dados de treinamento e dados de validação manualmente. A função é bem simples e só admite 8 combinações de 0's e 1's.\n",
    "Separaremos da seguinte forma, escolhida aleatoriamente:\n",
    "\n",
    "<table>\n",
    "  <tl>\n",
    "      <td>Entradas</td>\n",
    "      <td>Função</td>\n",
    "  </tl>\n",
    "  <tr>\n",
    "    <td>000</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>001</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>010</td>\n",
    "    <td>Validação</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>011</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>100</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>101</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>110</td>\n",
    "    <td>Validação</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>111</td>\n",
    "    <td>Treino</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "### Construção dos vetores de treino e validação.\n",
    "`x_treino` e `y_treino` serão os dados usados para treinar a rede. Já `x_teste` e `y_teste` serão usados para valida-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução da função 2\n",
    "Fazer regressão não linear não é tão simples assim. Por isso, faremos uso de uma classe do Keras chamada `KerasRegressor` para nos auxiliar nesta tarefa. Primeiro vamos deixar tudo pronto para usá-la definindo a função que queremos simular e o `modelo()` da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtd_ponto = 300  # QUANTIDADE DE PONTOS\n",
    "def objetivo(x):\n",
    "    return np.cos(2*np.pi*x)*np.sinc(x)/(1-(4*x)**2)\n",
    "\n",
    "def modelo():\n",
    "    model= km.Sequential()\n",
    "    model.add(kl.Dense(20, input_dim=1, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(kl.Dense(20, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(kl.Dense(20, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(kl.Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando dados de treinamento\n",
    "A rede neural que estamos contruindo deve retornar os valores da função dita anteriormente, logo, os dados de treinamento são valores de x quaisquer e valores calculados de $f(x)$.\n",
    "O código abaixo criará o vetor com 400 valores de x no intervalo $[0, 4\\pi]$ dispersos linearmente e o vetor y será preenchido com elementos $y_{i} = f(x_{i})$.\n",
    "\n",
    "Os dados são escalados usando a classe StandardScaler().\n",
    "OBS.: \n",
    "\n",
    "**Escalar** um vetor é soma-lo de uma constante e depois multiplica-lo por uma constante.\n",
    "**Normalizar** um vetor é dividir todos elementos pela sua norma.\n",
    "**Padronizar** um vetor geralmente significa subtrair um medida de localização (média) e dividir por uma medida de escala (desvio padrão).\n",
    "\n",
    "Fonte: [Should I normalize/standardize/rescale the data?](http://www.faqs.org/faqs/ai-faq/neural-nets/part2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 4*np.pi, qtd_ponto)[np.newaxis].T  # cria um vetor coluna\n",
    "y = objetivo(x)  # Também é vetor coluna\n",
    "sc_X = StandardScaler()\n",
    "sc_Y = StandardScaler()\n",
    "x_treino = sc_X.fit_transform(x)\n",
    "y_treino = sc_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui criamos um objeto estimador. Seus parâmetros são: \n",
    "\n",
    "* Função que modela a rede\n",
    "* Número de épocas: Quantidade de vezes que ocorrerá o \"backpropagation\"\n",
    "* Tamanho do \"batch\"\n",
    "* verbose: um inteiro indicando o que deve ser impresso na tela, não é essencial ao projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9965\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9635\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9165\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.8405\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7591\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.7575\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.6606\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.6072\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5783\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.5249\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4943\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4481\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4779\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.4451\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4025\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.4008\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.3545\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3558\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2922\n",
      "Epoch 20/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2585\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2297\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.3480\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2340\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2154\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1700\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1793\n",
      "Epoch 27/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1747\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1626\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2571\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1375\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3765\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.1424\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1453\n",
      "Epoch 34/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1466\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.1792\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.1015\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1235\n",
      "Epoch 38/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0970\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0993\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0827\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1325\n",
      "Epoch 42/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.1529\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.0861\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0651\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0934\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0366\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0602\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 49/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0384\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0443\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0884\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0460\n",
      "Epoch 53/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0428\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0163\n",
      "Epoch 55/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0229\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0321\n",
      "Epoch 57/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4437\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.9127\n",
      "Epoch 59/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.6746\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.5624\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.5241\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4991\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4667\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4306\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.4061\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3766\n",
      "Epoch 67/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3550\n",
      "Epoch 68/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3368\n",
      "Epoch 69/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.3198\n",
      "Epoch 70/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2870\n",
      "Epoch 71/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2970\n",
      "Epoch 72/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.3203\n",
      "Epoch 73/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2633\n",
      "Epoch 74/100\n",
      "300/300 [==============================] - 1s 3ms/step - loss: 0.2385\n",
      "Epoch 75/100\n",
      "300/300 [==============================] - 1s 2ms/step - loss: 0.2002\n",
      "Epoch 76/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2755\n",
      "Epoch 77/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2545\n",
      "Epoch 78/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1997\n",
      "Epoch 79/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1943\n",
      "Epoch 80/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1815\n",
      "Epoch 81/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1913\n",
      "Epoch 82/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1583\n",
      "Epoch 83/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1299\n",
      "Epoch 84/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1730\n",
      "Epoch 85/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1262\n",
      "Epoch 86/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.1284\n",
      "Epoch 87/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1462\n",
      "Epoch 88/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1017\n",
      "Epoch 89/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0980\n",
      "Epoch 90/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1054\n",
      "Epoch 91/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0881\n",
      "Epoch 92/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1135\n",
      "Epoch 93/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0988\n",
      "Epoch 94/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.1465\n",
      "Epoch 95/100\n",
      "300/300 [==============================] - 0s 2ms/step - loss: 0.0775\n",
      "Epoch 96/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0990\n",
      "Epoch 97/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0647\n",
      "Epoch 98/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0490\n",
      "Epoch 99/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0726\n",
      "Epoch 100/100\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.0399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0e942f1940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimador = KerasRegressor(build_fn=modelo, epochs=100, batch_size=3, verbose=1)  # quanto menor o batch-size, melhor a precisão do resultado\n",
    "H = estimador.fit(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando dados para validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interv = (x[1] - x[0])/2  # Metade do intervalo entre dois pontos em x_treino\n",
    "x = np.linspace(interv, 4*np.pi+interv, qtd_ponto)[np.newaxis].T\n",
    "y = objetivo(x)\n",
    "x_teste = sc_X.fit_transform(x)\n",
    "y_teste = sc_Y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizando resultado. Curva em azul é o gabarito, a verde é o estimado pela rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 784us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valores_norm = estimador.predict(x_teste)  # valores normalizados\n",
    "valores = sc_Y.inverse_transform(valores_norm)\n",
    "\n",
    "plt.plot(x, y, 'bo')\n",
    "plt.plot(x, valores, 'g+')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução da função 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
